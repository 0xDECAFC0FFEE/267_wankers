{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import surprise\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    '''\n",
    "    Read the ratings data into pandas dataframe. Will drop Timestamp and return a train test split. \n",
    "    '''\n",
    "    df = pd.read_csv('ml-1m/ratings.dat', sep='::', names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "    df = df.drop(columns='Timestamp')\n",
    "    train=df.sample(frac=0.8,random_state=200) \n",
    "    test=df.drop(train.index)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = read_data('ml-1m/ratings.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYSVD:\n",
    "    def __init__(self, K = 20, epoch = 20, lr = 0.007, reg = 0.002):\n",
    "        self.K = K\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "            \n",
    "    def predict(self, user_id, item_id): \n",
    "        self.bi.setdefault(item_id,0)  \n",
    "        self.bu.setdefault(user_id,0)  \n",
    "        self.qi.setdefault(item_id,np.random.random((1,self.K)) + 0.1)  \n",
    "        self.pu.setdefault(user_id,np.random.random((1,self.K)) + 0.1)\n",
    "        score = 0\n",
    "        try:\n",
    "            score = self.avg + self.bu[user_id] + self.bi[item_id] + np.dot(self.qi[item_id], self.pu[user_id].T)\n",
    "        except:\n",
    "            print (self.avg)\n",
    "            print (self.bu[user_id])\n",
    "            print (self.bi[item_id])\n",
    "            print (self.qi[item_id])\n",
    "            print (self.pu[user_id])\n",
    "            raise\n",
    "        return score\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        print (\"Fitting starts\")\n",
    "        self.train_df = train_df        \n",
    "        self.avg = np.average(self.train_df['Rating'])\n",
    "#         self.bi = np.zeros(item_num, np.double)\n",
    "#         self.bu = np.zeros(user_num, np.double)\n",
    "#         self.qi = np.zeros((item_num, self.K), np.double)+.1\n",
    "#         self.pu = np.zeros((user_num, self.K), np.double)+.1\n",
    "        self.bi={}  \n",
    "        self.bu={}  \n",
    "        self.qi={}  \n",
    "        self.pu={}\n",
    "        for i, row in tqdm(self.train_df.iterrows()):\n",
    "            user_id = row['UserID']\n",
    "            item_id = row['MovieID']\n",
    "            self.bi.setdefault(user_id,0)  \n",
    "            self.bu.setdefault(user_id,0)  \n",
    "            self.qi.setdefault(item_id,np.zeros((1,self.K)) + 0.1)  \n",
    "            self.pu.setdefault(user_id,np.zeros((1,self.K)) + 0.1) \n",
    "        print (\"Fitting ends\")\n",
    "    \n",
    "    def train(self, train_df):\n",
    "        self.train_df = train_df        \n",
    "        user_num = self.train_df.shape[0]\n",
    "        item_num = self.train_df.shape[1]\n",
    "\n",
    "        for i in tqdm(range(self.epoch)):\n",
    "            print(\"Training epoch {}\".format(i))\n",
    "            for j, row in self.train_df.iterrows():\n",
    "                user_id = row['UserID']\n",
    "                item_id = row['MovieID']\n",
    "                rating = row['Rating']\n",
    "                rui = self.avg + self.bu[user_id] + self.bi[item_id] + np.dot(self.qi[item_id], self.pu[user_id].T)\n",
    "                eui = rating - rui\n",
    "                \n",
    "                self.bu[user_id] += self.lr * (eui - self.reg * self.bu[user_id])\n",
    "                self.bi[item_id] += self.lr * (eui - self.reg * self.bi[item_id])\n",
    "                self.pu[user_id] += self.lr * (eui * self.qi[item_id] - self.reg * self.pu[user_id])\n",
    "                self.qi[item_id] += self.lr * (eui * self.pu[user_id] - self.reg * self.qi[item_id])\n",
    "            self.lr *= 0.93\n",
    "       \n",
    "    def test(self, test_df):   \n",
    "        rmse=0.0\n",
    "        mae=0  \n",
    "        for j, row in test_df.iterrows():\n",
    "            user_id = row['UserID']\n",
    "            item_id = row['MovieID']\n",
    "            rating = row['Rating']\n",
    "            eui=rating-self.predict(user_id, item_id)  \n",
    "            rmse+=eui**2  \n",
    "            mae+=abs(eui)\n",
    "        N = test_df.shape[0]\n",
    "        return rmse, mae\n",
    "    \n",
    "    def read_model(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting starts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b0871c35464f0f947b74235e5abc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting ends\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724398185e4f4b7f9974421b3b1de107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "Training epoch 1\n",
      "Training epoch 2\n",
      "Training epoch 3\n",
      "Training epoch 4\n",
      "Training epoch 5\n",
      "Training epoch 6\n",
      "Training epoch 7\n",
      "Training epoch 8\n",
      "Training epoch 9\n",
      "Training epoch 10\n",
      "Training epoch 11\n",
      "Training epoch 12\n",
      "Training epoch 13\n",
      "Training epoch 14\n",
      "Training epoch 15\n",
      "Training epoch 16\n",
      "Training epoch 17\n",
      "Training epoch 18\n",
      "Training epoch 19\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[158371.950798]]), array([[140078.92807162]]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MYSVD(epoch = 20)\n",
    "model.fit(train_data)\n",
    "model.train(train_data)\n",
    "model.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse is 0.889772, ase is 0.700248\n"
     ]
    }
   ],
   "source": [
    "print('rmse is {0:3f}, ase is {1:3f}'.format(np.sqrt(158371.950798/N),140078.92807162/N))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svd.model', 'wb') as svd_model:\n",
    "    pickle.dump(model, svd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svd.model', 'rb') as svd_model:\n",
    "    # Step 3\n",
    "    model_read = pickle.load(svd_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[158371.950798]]), array([[140078.92807162]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_read.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
